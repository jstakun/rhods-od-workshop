= 1.1 Setting up your Data Science Project

include::_attributes.adoc[]

xref:index.adoc[Back to the introduction]

== The OpenShift Data Science Dashboard


NOTE: We're going to refer to _Red Hat OpenShift Data Science_ as RHODS throughout this workshop.

You should be logged into *Red Hat OpenShift Data Science*, and be able to see the dashboard, that looks like this:

image::notebooks/dashboard.png[alt text]

NOTE: If you're at the OpenShift Web Console and need to navigate back to the OpenShift Data Science Dashboard, use the *Application Switcher* Icon in the top right of the navigation bar.

image::notebooks/ocp-console-app-switcher.png[alt text, 400]


*Red Hat OpenShift Data Science* brings you on-demand Jupyter Notebook environments. Don't worry if you've never used notebooks before as this workshop will start with a small tutorial on what they are and how to use them.

* Now that you are logged into to *Red Hat OpenShift Data Science*, navigate to Data Science Projects in the left menu. Here you can see the list of existing Projects that you have access to. 

NOTE: Projects allow you and your team to organize and collaborate on resources within separated namespaces.

* Select `Create new project`. You can now see the initial state of an empty Project. There are four type of Project resources, which we will create throughout the next steps:

** *Workbenches* are instances of your development and experimentation environment. Workbenches typically contain IDEs such as JupyterLab and Visual Studio Code.

** A *Data Storage* is a volume that persists the files and data you're working on within a workbench. A workbench has access to one or more data storage instances.

** *Data Connections* contain configuration parameters that are required to connect to a data source such as an S3 bucket.

** *Model Servers* allow you to quickly serve a trained model for real-time inference. There is one model server per Project, and one model server can host multiple models.

* Let's create a workbench. Click on _Create_ in the workbench section to proceed to the workbench configuration page. Choose the following settings:

** Choose an arbitrary *name* such as _development_.

** Under *workbench image* select `Generic data science`.

** Under *workbench size* select `small`.

** Leave the *environment variables* section empty. We will populate the workbench's environment variables through a data connection later.

** Under *persistence* select `Create new persistent storage` with the default values.

** Click *Create* to initialize your workbench.

* You're redirected to the Project page where you can see the status of your new workbench. The first time it's initialized it will take about 1-2 minutes to start up. Subsequent starts will be faster.

* You can also see a new data storage instance that has been provisioned together with your workbench. All files you create in your workbench will be persisted in this data storage.

* Let's create a data connection to gain access to the object detection model. Under _Data Connection_ select `Create`. In the configuration page, populate the fields as follows:

** Enter an arbitrary *name* like `S3 bucket`.

** Enter the *AWS Access Key* and *AWS Secret Key* TODO.

** Under *S3 Endpoint* enter TODO.

** Under *AWS_S3_BUCKET* enter TODO.

** In the *Connected workbenches* dropdown menu select your provisioned workbench.

** Select *Create* to instantiate the data connection. This will cause your workbench to restart, but this time the workbench will be up and running within a few seconds.

You're now all set. You've configured your first Data Science Project. To start working with the object detection model, select `Enter` next to your running workbench instance and
xref:1-02-jupyter-env.adoc[head to the next section.]


